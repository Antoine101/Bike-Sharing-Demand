{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf10b8a",
   "metadata": {},
   "source": [
    "# <center>Bike Sharing Demand</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e92fe6",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\">Introduction</a></span></li><li><span><a href=\"#Import-des-Librairies\" data-toc-modified-id=\"Import-des-Librairies-2\">Import des Librairies</a></span></li><li><span><a href=\"#Configuration-des-Paramètres-d'Affichage-du-Notebook\" data-toc-modified-id=\"Configuration-des-Paramètres-d'Affichage-du-Notebook-3\">Configuration des Paramètres d'Affichage du Notebook</a></span></li><li><span><a href=\"#Import-du-Dataset\" data-toc-modified-id=\"Import-du-Dataset-4\">Import du Dataset</a></span></li><li><span><a href=\"#Extraction-d'Informations-Temporelles-de-datetime\" data-toc-modified-id=\"Extraction-d'Informations-Temporelles-de-datetime-5\">Extraction d'Informations Temporelles de <code>datetime</code></a></span></li><li><span><a href=\"#Conversion-des-Types-des-Colonnes\" data-toc-modified-id=\"Conversion-des-Types-des-Colonnes-6\">Conversion des Types des Colonnes</a></span></li><li><span><a href=\"#Nettoyage-du-Dataset\" data-toc-modified-id=\"Nettoyage-du-Dataset-7\">Nettoyage du Dataset</a></span></li><li><span><a href=\"#Analyse-du-Dataset\" data-toc-modified-id=\"Analyse-du-Dataset-8\">Analyse du Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Évolution-temporelle-du-nombre-de-locations\" data-toc-modified-id=\"Évolution-temporelle-du-nombre-de-locations-8.1\">Évolution temporelle du nombre de locations</a></span></li><li><span><a href=\"#Influence-de-la-saison-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-la-saison-sur-le-nombre-total-de-locations-8.2\">Influence de la saison sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-du-jour-de-la-semaine-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-du-jour-de-la-semaine-sur-le-nombre-total-de-locations-8.3\">Influence du jour de la semaine sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-de-l'heure-de-la-journée-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-l'heure-de-la-journée-sur-le-nombre-total-de-locations-8.4\">Influence de l'heure de la journée sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-des-vacances-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-des-vacances-sur-le-nombre-total-de-locations-8.5\">Influence des vacances sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-de-la-météo-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-la-météo-sur-le-nombre-total-de-locations-8.6\">Influence de la météo sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-de-la-température-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-la-température-sur-le-nombre-total-de-locations-8.7\">Influence de la température sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-de-l'humidité-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-l'humidité-sur-le-nombre-total-de-locations-8.8\">Influence de l'humidité sur le nombre total de locations</a></span></li><li><span><a href=\"#Influence-de-la-vitesse-du-vent-sur-le-nombre-total-de-locations\" data-toc-modified-id=\"Influence-de-la-vitesse-du-vent-sur-le-nombre-total-de-locations-8.9\">Influence de la vitesse du vent sur le nombre total de locations</a></span></li><li><span><a href=\"#Résumé-des-observations\" data-toc-modified-id=\"Résumé-des-observations-8.10\">Résumé des observations</a></span></li><li><span><a href=\"#Analyse-de-Corrélations\" data-toc-modified-id=\"Analyse-de-Corrélations-8.11\">Analyse de Corrélations</a></span></li></ul></li><li><span><a href=\"#Préparation-du-Jeu-de-Données\" data-toc-modified-id=\"Préparation-du-Jeu-de-Données-9\">Préparation du Jeu de Données</a></span><ul class=\"toc-item\"><li><span><a href=\"#Séparation-en-jeux-d'entraînement-et-de-test\" data-toc-modified-id=\"Séparation-en-jeux-d'entraînement-et-de-test-9.1\">Séparation en jeux d'entraînement et de test</a></span></li><li><span><a href=\"#Feature-Engineering\" data-toc-modified-id=\"Feature-Engineering-9.2\">Feature Engineering</a></span></li><li><span><a href=\"#Création-du-preprocessor\" data-toc-modified-id=\"Création-du-preprocessor-9.3\">Création du <code>preprocessor</code></a></span></li></ul></li><li><span><a href=\"#Entraînement-et-Évaluation-de-Modèles\" data-toc-modified-id=\"Entraînement-et-Évaluation-de-Modèles-10\">Entraînement et Évaluation de Modèles</a></span><ul class=\"toc-item\"><li><span><a href=\"#Métriques-d'Évaluation\" data-toc-modified-id=\"Métriques-d'Évaluation-10.1\">Métriques d'Évaluation</a></span></li><li><span><a href=\"#Régression-Linéaire\" data-toc-modified-id=\"Régression-Linéaire-10.2\">Régression Linéaire</a></span></li><li><span><a href=\"#Decision-Tree\" data-toc-modified-id=\"Decision-Tree-10.3\">Decision Tree</a></span></li><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-10.4\">Random Forest</a></span></li><li><span><a href=\"#Gradient-Boosting\" data-toc-modified-id=\"Gradient-Boosting-10.5\">Gradient Boosting</a></span></li><li><span><a href=\"#Comparaison-des-Modèles\" data-toc-modified-id=\"Comparaison-des-Modèles-10.6\">Comparaison des Modèles</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-11\">Conclusion</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8043156",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589ce2de",
   "metadata": {},
   "source": [
    "Le but de ce projet consiste à entraîner un modèle capable de prédire le nombre de vélos loués à n'importe quel temps t dans des bornes libres-services de la ville (système type Vélib'). La variable cible à prédire est ici la variable `count`.\n",
    "\n",
    "Voici un descriptif de l'ensemble des variables du jeu de données:\n",
    "* `datetime` - date et heure du relevé \n",
    "* `season` - 1 = printemps , 2 = été, 3 = automne, 4 = hiver \n",
    "* `holiday` – indique si le jour est un jour de vacances scolaires \n",
    "* `workingday` - indique si le jour est travaillé (ni week-end ni vacances) \n",
    "* `weather` - 1: Dégagé à nuageux, 2 : Brouillard, 3 : Légère pluie ou neige, 4 : Fortes averses ou neiges \n",
    "* `temp` – température en degrés Celsius \n",
    "* `atemp` – température ressentie en degrés Celsius \n",
    "* `humidity` – taux d’humidité \n",
    "* `windspeed` – vitesse du vent \n",
    "* `casual` - nombre de locations d’usagers non abonnés \n",
    "* `registered` – nombre de locations d’usagers abonnés \n",
    "* `count` – nombre total de locations de vélos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c601ac",
   "metadata": {},
   "source": [
    "## Import des Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aacbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import calendar\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c920d7e",
   "metadata": {},
   "source": [
    "## Configuration des Paramètres d'Affichage du Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197f482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b1da5",
   "metadata": {},
   "source": [
    "## Import du Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93842652",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"data/velo.csv\")\n",
    "dataset.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db1170",
   "metadata": {},
   "source": [
    "Le jeu de données ne comporte pas de valeurs manquantes. \n",
    "\n",
    "Affichons les premières lignes pour nous faire une meilleure idée des données qu'il contient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a161e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce487687",
   "metadata": {},
   "source": [
    "## Extraction d'Informations Temporelles de `datetime`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e814a0d2",
   "metadata": {},
   "source": [
    "Avant de passer à l'exploration du dataset, nous extrayons l'année, le jour et l'heure des timestamps de la colonne `datetime`. Nous créons ainsi trois nouvelles colonnes `year`, `weekday` et `hour`.\n",
    "\n",
    "Plutôt que d'extraire le jour en chiffres, nous extrayons le nom du jour de la semaine. Cela nous permet d'avoir une colonne avec moins de catégories. Il nous apparait également plus pertinent de pouvoir distinguer les différents jours de la semaine. On s'attendra à avoir des différences dans le nombre de locations entre la semaine et le weekend. Il pourrait également y avoir une différence entre certains jours de la semaine. Les Mercredi et les Jeudi étant des jours préférés pour le télétravail, il se pourrait que les utilisateurs réguliers du service qui l'utilise pour leur commuting ne loue pas de vélo sur ces jours.\n",
    "\n",
    "Nous n'exportons pas le mois car cela créerai trop de catégories. L'évolution de la demande de location au long de l'année est déjà portée par les colonnes `season` et `holiday`.\n",
    "\n",
    "La colonne `hour`, pour sa part, est modifiée plus bas lors de l'étape de feature engineering lors de laquelle nous regroupons les heures en quatre périodes distinctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4d776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion de la colonne `datetime` au type datetime\n",
    "dataset[\"datetime\"] = pd.to_datetime(dataset[\"datetime\"])\n",
    "# Extraction de l'année des timestamps et insertion de la nouvelle colonne `year` dans le dataset\n",
    "year = dataset[\"datetime\"].dt.year\n",
    "dataset.insert(loc=1, column=\"year\", value=year)\n",
    "# Extraction du jour de la semaine des timestamps et insertion de la nouvelle colonne `weekday` dans le dataset\n",
    "weekday = dataset[\"datetime\"].apply(lambda x: x.weekday()+1)\n",
    "dataset.insert(loc=3, column=\"weekday\", value=weekday)\n",
    "# Extraction de l'heure des timestamps et insertion de la nouvelle colonne `hour` dans le dataset\n",
    "hour = dataset[\"datetime\"].dt.hour\n",
    "dataset.insert(loc=6, column=\"hour\", value=hour)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79691a",
   "metadata": {},
   "source": [
    "## Conversion des Types des Colonnes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a132d666",
   "metadata": {},
   "source": [
    "Nous convertissons ensuite le type des colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fefe4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = [\n",
    "    \"holiday\",\n",
    "    \"workingday\",\n",
    "    \"weather\"\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    dataset[col] = dataset[col].astype(\"category\")\n",
    "    \n",
    "dataset[\"temp\"] = dataset[\"temp\"].astype(\"int\")\n",
    "dataset[\"atemp\"] = dataset[\"atemp\"].astype(\"int\")\n",
    "dataset[\"windspeed\"] = round(dataset[\"windspeed\"], 1)\n",
    "\n",
    "dataset.info(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730e3b2",
   "metadata": {},
   "source": [
    "## Nettoyage du Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb90555",
   "metadata": {},
   "source": [
    "Comme nous avons pu le voir plus haut, le jeu de données ne présente pas de valeurs manquantes. Aucune action d'imputation ou de suppressions de variables ou d'observations n'est donc nécessaire.\n",
    "\n",
    "Pour ce qui est des outliers, nous calculons et affichons quelques statistiques sur les colonnes numériques, pour nous permettre de détecter leur présence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ea737",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe(percentiles=[.25, .50, .75, .95])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaf00b8",
   "metadata": {},
   "source": [
    "Il semble pas qu'il n'y ai pas de valeurs abhérantes dans notre jeu de données.\n",
    "Les valeurs maximales de `windspeed`, de `casual` et de `registered` sont plutôt élévées par rapport à leur 95e centile et leurs médianes respectives.\n",
    "Néanmoins, après quelques recherches, il semblerait qu'une vitesse du vent de 57mph est observable dans le cas de tempêtes d'intensité modérée. Pour ce qui est des maximums de location, il se peut qu'un évènement particulier est favorisé ceux-ci (grêves des transports, journée sans voitures, ...).\n",
    "\n",
    "Nous laissons ainsi le jeu de données tel quel et passons à son analyse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2891df54",
   "metadata": {},
   "source": [
    "## Analyse du Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0563afd",
   "metadata": {},
   "source": [
    "Le jeu de données est désormais prêt à être analysé. Dans cette section, nous nous intéressons à l'évolution du nombre total de locations (variable à prédire `count`) en fonction des différentes variables prédictives. Nous effectuons aussi une analyse de corrélations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af289c53",
   "metadata": {},
   "source": [
    "### Évolution temporelle du nombre de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec472ef",
   "metadata": {},
   "source": [
    "Commençons par tracer l'évolution temporelle du nombre de locations en ne prenant en compte que les timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6222c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ts = dataset[\"datetime\"].min()\n",
    "last_ts = dataset[\"datetime\"].max()\n",
    "\n",
    "print(f\"First recorded timestamp: {first_ts}\")\n",
    "print(f\"Last recorded timestamp: {last_ts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2644c6ec",
   "metadata": {},
   "source": [
    "Le dataset couvre une période d'environ deux ans, à raison d'un enregistrement par heure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7142e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,15))\n",
    "sns.scatterplot(x=\"datetime\", y=\"count\", data=dataset)\n",
    "sns.scatterplot(x=\"datetime\", y=\"registered\", data=dataset)\n",
    "sns.scatterplot(x=\"datetime\", y=\"casual\", data=dataset)\n",
    "plt.legend([\"count\", \"registered\", \"casual\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c8c8dc",
   "metadata": {},
   "source": [
    "Nous pouvons clairement observer une saisonalité dans l'évolution du nombre total de locations au sein d'une même année, ainsi qu'un offset entre l'année 2011 et l'année 2012, cette dernière ayant enregistré significativement plus de locations.\n",
    "\n",
    "Il apparaît que le nombre de locations `casual` a moins augmenté d'une année sur l'autre que le nombre de locations `registered`. Ce type de service est très axé sur les \"commuters\". Il semble donc logique que, suite à une campagne d'informations et de publicité, le nombre d'utilisaterus réguliers ai augmenté d'une année sur l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214248e7",
   "metadata": {},
   "source": [
    "### Influence de la saison sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b42e701",
   "metadata": {},
   "source": [
    "Ci-dessous, nous traçons le nombre total de locations par jour pour chaque saison et ce pour l'année 2011 et 2012 pour voir si une tendance se répète d'une année sur l'autre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbbe50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(x=\"season\", y=\"count\", data=dataset, hue=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383fdd1a",
   "metadata": {},
   "source": [
    "Nous observons bien la saisonalité que nous avions déjà observée sur le graphe précédent. Sur les deux années consécutives, le printemps et l'été ont, logiquement, été les deux saisons où le nombre de locations-jour étaient le plus élévé. Cela est surement dû à la météo plus favorable qui pousse plus de gens à utiliser ce moyen de transports tant pour le commuting que pour le loisir et à l'affluence de touristes sur ces deux saisons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ec96d5",
   "metadata": {},
   "source": [
    "### Influence du jour de la semaine sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ca3dc",
   "metadata": {},
   "source": [
    "Intéressons-nous maintenant à l'évolution du nombre total de locations au cours d'une semaine. Quels sont les jours pour lesquels la demande est la plus forte?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cd24c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "ax = sns.boxplot(x=\"weekday\", y=\"count\", data=dataset, hue=\"year\")\n",
    "ax.set_xticklabels([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbbdca6",
   "metadata": {},
   "source": [
    "Nous observons une tendance légèrement différente entre l'année 2011 et l'année 2012.\n",
    "\n",
    "Sur l'année 2011, le nombre total de locations était, en se basant sur la médiane pour cette période, plus élevé les Lundi, Mardi, Jeudi et Vendredi. Le Mercredi étant un jour préféré pour le télé-travail, il est possible que les utilisateurs réguliers aient eu en moyenne moins recours au service de location ce jour-ci.\n",
    "Sur cette même année, la demande semblait plus faible les Samedi et Dimanche. Cela était peut-être dû à une part moins importante des utilisateurs `casual` par rapport aux utilisateurs `registered`.\n",
    "\n",
    "Pour l'année 2012, la demande était relativement constante au cours des cinq jours travaillés de la semaine, avec une augmentation sensible à l'approche du week-end. La plus grande variation de la demande les Samedi traduit peut-être de l'influence de la météo sur l'utilisation de ce service pour le loisir sur ce jour de weekend. Les Dimanche, la demande était significativement plus faible.\n",
    "\n",
    "Dans la continuité du graphe précédent, nous pouvons tracer le nombre total de locations en fonction seulement du statut du jour (travaillé ou non) en prenant en compte la colonne `workingday`, originellement présente dans le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13170dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"workingday\", y=\"count\", data=dataset, hue=\"year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68b52b",
   "metadata": {},
   "source": [
    "### Influence de l'heure de la journée sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9fb9f12",
   "metadata": {},
   "source": [
    "Il est également intéressant de regarder l'évolution du nombre total de locations en fonction de l'heure de la journée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81917c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x=\"hour\", y=\"count\", data=dataset, hue=\"year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e447e",
   "metadata": {},
   "source": [
    "Nous observons une tendance similaire pour les années 2011 et 2012.\n",
    "Nous pouvons noter deux pics de demande sur les périodes horaires correspondant au commuting, de 6h à 9h et de 16h à 20h.\n",
    "Entre ces deux pics, la demande est moyennement élevée et peu variable.\n",
    "Après 20h, le nombre de locations ne cesse de baisser jusqu'à atteindre un minimum à 4h du matin.\n",
    "\n",
    "Nous nous servirons de cette analyse lors de la partie feature engineering pour découper la journée en périodes et rendre la colonne `hour` plus exploitable par nos modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced7a6bf",
   "metadata": {},
   "source": [
    "### Influence des vacances sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dce362",
   "metadata": {},
   "source": [
    "Les vacances sont également spécifiées dans le dataset, par le biais de la colonne `holiday`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"holiday\", y=\"count\", data=dataset, hue=\"year\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5938f43",
   "metadata": {},
   "source": [
    "Le nombre total de locations n'est pas significativement plus important ou plus faible pendant les vacances. Pendant les périodes de vacances, il est possible que la location touristique ou de loisir compense la baisse du commuting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33bc990",
   "metadata": {},
   "source": [
    "### Influence de la météo sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1e23fe",
   "metadata": {},
   "source": [
    "L'information sur la météo est également dans le jeu de données. La variable `weather` donne une indication de la météo au moment de l'enregistrement en 4 niveaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43688940",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x=\"weather\", y=\"count\", data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd1f3f1",
   "metadata": {},
   "source": [
    "Comme nous pouvions nous y attendre, plus la météo est clémente, plus le nombre total de locations est élevé. À l'inverse, plus la météo est défavorable, moins la demande pour ce service est forte."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c56325",
   "metadata": {},
   "source": [
    "### Influence de la température sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93eaf75c",
   "metadata": {},
   "source": [
    "Dans la lignée de l'analyse précédente, nous pouvons également observer l'évolution du nombre total de locations en fonction de la température."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d6ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.scatterplot(x=\"atemp\", y=\"count\", data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1766953",
   "metadata": {},
   "source": [
    "Globalement, des températures plus clémentes favorisent l'utilisation de ce service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5260ee",
   "metadata": {},
   "source": [
    "### Influence de l'humidité sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f30441",
   "metadata": {},
   "source": [
    "Nous pouvons également analyser l'évolution du nombre total de locations en fonction de l'humidité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b144f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.scatterplot(x=\"humidity\", y=\"count\", data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710b477",
   "metadata": {},
   "source": [
    "L'impact de l'humidité est moins flagrant, même si l'on peut tout de même déceler une baisse de la demande pour des taux d'humidité plus élevés."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28ab7ff",
   "metadata": {},
   "source": [
    "### Influence de la vitesse du vent sur le nombre total de locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc7e31",
   "metadata": {},
   "source": [
    "Enfin, nous terminons par l'analyse de l'impact de la vitesse du vent sur le nombre total de locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d37005",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.scatterplot(x=\"windspeed\", y=\"count\", data=dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a2521",
   "metadata": {},
   "source": [
    "Il apparaît que le nombre de locations est plus faible lorsque la vitesse du vent est plus élevée. La variable `windspeed` pourrait donc être pertinente pour notre tentative de prédiction du nombre de locations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e6d281",
   "metadata": {},
   "source": [
    "### Résumé des observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c44fd",
   "metadata": {},
   "source": [
    "L'analyse de l'influence de chaque variable prédictice sur la variable à prédire `count` nous a permis de faire les observations suivantes:\n",
    "- l'évolution temporelle du nombre total de locations a globalement augmenté d'une année sur l'autre.\n",
    "- celle-ci respecte une seasonalité au cours de l'année.\n",
    "- la saison impact la demande, probablement en lien avec la météo qui est plus clémente pour certaines saisons plutôt que pour d'autres.\n",
    "- le jour de la semaine peut être pertinent à prendre en compte car la demande pour ce service varie en fonction de celui-ci.\n",
    "- le caractère travaillé ou non du jour influe également sur la demande.\n",
    "- le nombre total de locations varie de façon encore plus importante en fonction de l'heure de la journée.\n",
    "- les vacances impactent moins la demande, et l'on peut supposer que les demandes pour le commuting et pour le loisir s'équilibrent.\n",
    "- La météo a également un fort impact sur le nombre total de locations.\n",
    "- Globalement, plusieurs variables de ce jeu de données portent des informations très proches (`season` et `weather` par exemple).\n",
    "\n",
    "Dans la prochaine section, nous menons une étude de corrélations sur le jeu d'entraînement afin de voir quelles sont les variables prédictives qui ont une plus forte corrélation avec la variable à prédire `count`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeb94f2",
   "metadata": {},
   "source": [
    "### Analyse de Corrélations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1f6f4",
   "metadata": {},
   "source": [
    "Pour compléter l'analyse du jeu de données, nous menons une analyse de corrélations sur les variables numériques. Il s'agit alors de voir à quel degré les variables prédictices sont corrélées linéairement avec la variable à prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e17dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des variables numériques\n",
    "numerical_predictors = dataset.select_dtypes([np.number]).columns\n",
    "\n",
    "# Calcul de la matrice de corrélation sur les variables numériques\n",
    "corr = dataset[numerical_predictors].corr()\n",
    "\n",
    "# Création d'un masque pour masquer la symmétrie de la matrice\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Traçage la matrice de corrélation sous forme de heatmap\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "cmap = sns.diverging_palette(250, 0, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da50bbc5",
   "metadata": {},
   "source": [
    "Parmi les variables numériques, les variables `casual` et `registered` sont celles qui présentent le coefficient de corrélation linéaire le plus élevé. Cela est normal car la variable à prédire `count` est une addition de ces deux variables.\n",
    "\n",
    "Il apparait également que la température et l'humidité ont un coefficient de corrélation non négligeable, mais de signes opposés. La vitesse du vent, en revance, est très faiblement corrélée avec le nombre total de locations.\n",
    "\n",
    "Cela ne reflète pas, en tout cas pour l'humidité et la vitesse du vent, les observations faites dans la section précédente, dans laquelle nous voyions un plus fort impact de la vitesse du vent que de l'humidité.\n",
    "Toutefois, il ne s'agit là que de corrélation linéaire.\n",
    "\n",
    "Dans la prochaine section, nous préparons le jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f23f2",
   "metadata": {},
   "source": [
    "## Préparation du Jeu de Données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4707d",
   "metadata": {},
   "source": [
    "Nous préparons maintenant le jeu de données pour le rendre exploitable pour l'entraînement d'algorithmes de prédiction.\n",
    "\n",
    "Nous commençons par supprimer les colonnes suivantes:\n",
    "- `datetime`: car l'information temporelle est portée par d'autres variables telles que `weekday` ou `hour`.\n",
    "- `year`: car l'évolution observée de la demande d'une année sur l'autre ne sera pas forcément répétable et ne paraît donc pas être une variable prédictive pertinente.\n",
    "- `temp`: car la température ressentie est plus pertinente car la température théorique.\n",
    "- `casual` et `registered`: car elles servent directement à calculer la variable à prédire `count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680f655",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=[\"datetime\", \"year\", \"temp\", \"casual\", \"registered\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141ea6c",
   "metadata": {},
   "source": [
    "### Séparation en jeux d'entraînement et de test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0725264",
   "metadata": {},
   "source": [
    "Une fois le nombre de variables figé, nous pouvons séparer le jeu de données en un jeu de données d'entraînement et un jeu de données de test. \n",
    "Pour cela, nous décidons de réserver 20% des observations au jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7667e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"count\"\n",
    "\n",
    "y = dataset[target]\n",
    "X = dataset[dataset.columns.difference([target])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=64)\n",
    "\n",
    "print(f\"Number of train samples: {len(X_train)}\")\n",
    "print(f\"Number of test samples: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8509ae6",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450a3a6b",
   "metadata": {},
   "source": [
    "Une fois le jeu de données séparé, nous pouvons effectuer du feature engineering sur le jeu d'entraînement. Dans notre cas, nous allons transformer les variables temporelles `season`, `weekday` et `hour`. La nature cyclique et leur nombre élevé de catégories fait que l'encodage one-hot n'est pas le plus approprié.\n",
    "Au lieu d'encoder ces colonnes, nous allons créer à partir de chacune deux nouvelles colonnes qui seront le sinus et le cosinus de leurs valeurs.\n",
    "\n",
    "Nous créons une fonction custom qui permet de créer ces nouvelles colonnes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926e2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformation(column):\n",
    "    max_value = column.max()\n",
    "    sin_values = [math.sin((2*math.pi*x)/max_value) for x in list(column)]\n",
    "    cos_values = [math.cos((2*math.pi*x)/max_value) for x in list(column)]\n",
    "    return sin_values, cos_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b086415",
   "metadata": {},
   "source": [
    "Et nous l'appliquons aux variables temporelles, sur le jeu d'entraînement comme sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f1060",
   "metadata": {},
   "outputs": [],
   "source": [
    "cyclic_features = [\n",
    "    \"season\",\n",
    "    \"weekday\",\n",
    "    \"hour\"\n",
    "]\n",
    "\n",
    "for feature in cyclic_features:\n",
    "    X_train[f\"sin_{feature}\"], X_train[f\"cos_{feature}\"] = transformation(X_train[feature])\n",
    "    X_test[f\"sin_{feature}\"], X_test[f\"cos_{feature}\"] = transformation(X_test[feature])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eac1b3b",
   "metadata": {},
   "source": [
    "Enfin, nous supprimons les colonnes originelles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7983ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(cyclic_features, axis=1, inplace=True)\n",
    "X_test.drop(cyclic_features, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc811ba",
   "metadata": {},
   "source": [
    "### Création du `preprocessor`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8171b2",
   "metadata": {},
   "source": [
    "Nous créons enfin un pré-processeur. Via celui-ci, nous spécifions les pré-traitements à appliquer à chaque variable en fonction de son type avant les étapes d'entraînement du modèle ou de prédiction.\n",
    "\n",
    "Dans notre cas, nous spécifions de centrer et réduire toutes les variables numériques et d'opérer un encodage one-hot des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea033d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opérations de transformations pour les variables numériques\n",
    "numeric_transformer = StandardScaler()\n",
    "# Opérations de transformations pour les variables catégorielles\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# Colonnes numériques\n",
    "numeric_features = X_train.select_dtypes([np.number]).columns\n",
    "# Colonnes catégorielles\n",
    "categorical_features = X_train.select_dtypes([\"category\"]).columns\n",
    "\n",
    "# Instantiation du pré-processeur\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b70368",
   "metadata": {},
   "source": [
    "## Entraînement et Évaluation de Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f9131d",
   "metadata": {},
   "source": [
    "Nous sommes enfin prêt pour attaquer la phase de modélisation. Dans cette dernière section, nous entraînons plusieurs modèles plus ou moins complexes et comparons leurs performances sur la prédiction du jeu de test. Pour chaque modèle, nous chercherons à optimiser ses hyperparamètres pour obtenir la meilleure performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b54a42",
   "metadata": {},
   "source": [
    "### Métriques d'Évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ee9eaf",
   "metadata": {},
   "source": [
    "Nous choisissons de comparer les performances de nos modèles à l'aide de trois métriques:\n",
    "- RMSE\n",
    "- MAE\n",
    "- $r^{2}$\n",
    "\n",
    "La fonction ci-dessous nous permettra de calculer et d'afficher ces scores sur le jeu de test pour chaque modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(targets, predictions):\n",
    "    rmse = round(mean_squared_error(targets, predictions, squared=False), 1)\n",
    "    mae = round(mean_absolute_error(targets, predictions), 1)\n",
    "    r2 = round(r2_score(targets, predictions), 2)\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"R2: {r2}\")\n",
    "    return {\"rmse\":rmse, \"mae\":mae, \"r2\":r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571bf4b4",
   "metadata": {},
   "source": [
    "### Régression Linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ebf502",
   "metadata": {},
   "source": [
    "Le premier modèle que nous entraînons est une simple régression linéaire multiple. Nous créons d'abord le pipeline qui combine le pré-processeur, suivi du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aaef32",
   "metadata": {},
   "source": [
    "Puis nous entraînons le modèle sur le jeu d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d18a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du modèle\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur le jeu d'entraînement\n",
    "lr_train_predictions = lr_pipeline.predict(X_train)\n",
    "\n",
    "# Calcul et affichage des métriques de performance sur le jeu d'entraînement\n",
    "_ = metrics(y_train, lr_train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542266b0",
   "metadata": {},
   "source": [
    "Le score $r^{2}$ obtenu est très moyen. Le modèle linéaire semble ne pas être assez complexe pour modéliser les relations entre les variables prédictives et la variable à prédire.\n",
    "\n",
    "Nous évoluons le modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60681176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction sur le jeu de test\n",
    "lr_test_predictions = lr_pipeline.predict(X_test)\n",
    "\n",
    "# Calcul et affichage des métriques de performance sur le jeu de test\n",
    "lr_metrics = metrics(y_test, lr_test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58f1e2",
   "metadata": {},
   "source": [
    "Comme attendu, ce modèle ne performe pas bien en prédiction sur le jeu de test. Il est donc nécessaire de tester un modèle plus complexe qui arrive à capter les relations non-linéaires entre les variables prédictives et la variable à prédire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a66f280",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9505223f",
   "metadata": {},
   "source": [
    "Nous essayons maintenant un arbre de décision en régression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", DecisionTreeRegressor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa7fa9e",
   "metadata": {},
   "source": [
    "Ce modèle possède une multitude d'hyper-paramètres dont l'optimisation peut permettre une amélioration de ses performances. Nous choisissons, afin de réduire les temps de recherche et donc de calcul, d'implémenter une recherche aléatoire en validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dfe942",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random_grid = {\n",
    "        \"model__criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "        \"model__splitter\": [\"best\", \"random\"],\n",
    "        \"model__max_depth\": [None, 1, 2, 4, 8, 16, 32, 64, 128],\n",
    "        \"model__min_samples_split\": [int(x) for x in np.linspace(2, 50, num=10)],\n",
    "        \"model__min_samples_leaf\": [int(x) for x in np.linspace(1, 50, num=10)],\n",
    "        \"model__max_features\": [\"auto\", \"sqrt\", \"log2\"]\n",
    "}\n",
    "\n",
    "pp.pprint(dt_random_grid)\n",
    "\n",
    "total_conf = 1\n",
    "for _, value in dt_random_grid.items():\n",
    "    if isinstance(value, list):\n",
    "        total_conf *= len(value)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Total number of configurations: {total_conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afbc54a",
   "metadata": {},
   "source": [
    "Nous choisissons de ne tester qu'un certain nombre de ces configurations, aléatoirement. Le nombre de configurations à tester est spécifié via l'option `n_iter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb690eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_random_search = RandomizedSearchCV(\n",
    "                                    estimator=dt_pipeline, \n",
    "                                    param_distributions=dt_random_grid,\n",
    "                                    n_iter=100, \n",
    "                                    cv=5,\n",
    "                                    scoring=\"r2\",\n",
    "                                    verbose=1,\n",
    "                                    n_jobs=6,\n",
    "                                    random_state=42\n",
    "                                )\n",
    "\n",
    "dt_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5aedc59",
   "metadata": {},
   "source": [
    "Une fois l'entraînement terminé, nous affichons l'ensemble d'hyperparamètres qui produit le meilleur score en validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e6d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best score: {round(dt_random_search.best_score_, 2)}\")\n",
    "pp.pprint(dt_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74664c",
   "metadata": {},
   "source": [
    "Ce score r2 est significativement plus élevé que celui obtenu par une simple régression linéaire multiple.\n",
    "\n",
    "Nous pouvons également afficher l'importance relative de chaque feature dans la décision du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc843a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = dt_pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "dt_features_importance = np.around(dt_random_search.best_estimator_.named_steps[\"model\"].feature_importances_, decimals=2)\n",
    "\n",
    "dt_fi_df = pd.DataFrame(data={\"name\": features_name, \"importance\": dt_features_importance})\n",
    "\n",
    "sns.color_palette(\"pastel\")\n",
    "sns.barplot(x=\"importance\", y=\"name\", data=dt_fi_df, orient=\"h\")\n",
    "plt.xlabel(\"Relative Importance (%)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92fafb8",
   "metadata": {},
   "source": [
    "Nous pouvons voir que les features liées à l'heure du jour sont très au-dessus du lot. La température ainsi que le statut non-travaillé du jour sont également des features importantes pour le modèle.\n",
    "\n",
    "Voyons maintenant comment le modèle performe sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b21941",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_predictions = dt_random_search.predict(X_test)\n",
    "dt_metrics = metrics(y_test, dt_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06341960",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e419549",
   "metadata": {},
   "source": [
    "Passer d'un simple modèle linéaire à un arbre de décision nous a pratiquement permis de doubler notre score r2.\n",
    "Nous décidons désormais d'essayer une méthode ensembliste et d'entraîner un Random Forest.\n",
    "\n",
    "Comme précédemment, nous commençons par créer le pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbafa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f27496",
   "metadata": {},
   "source": [
    "Nous déterminons ensuite un espace d'hyper-paramètres parmi lequel piocher des configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb558670",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_grid = {\n",
    "    \"model__n_estimators\": [int(x) for x in np.linspace(start=50, stop=1000, num=10)],\n",
    "    \"model__max_features\": [\"auto\", \"sqrt\"],\n",
    "    \"model__max_depth\": [int(x) for x in np.linspace(2, 50, num=10)],\n",
    "    \"model__min_samples_split\": [int(x) for x in np.linspace(2, 50, num=10)],\n",
    "    \"model__min_samples_leaf\": [int(x) for x in np.linspace(1, 50, num=10)],\n",
    "    \"model__bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "pp.pprint(rf_random_grid)\n",
    "\n",
    "total_conf = 1\n",
    "for _, value in rf_random_grid.items():\n",
    "    if isinstance(value, list):\n",
    "        total_conf *= len(value)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Total number of configurations: {total_conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db7b779",
   "metadata": {},
   "source": [
    "Puis nous entraînons le modèle en validation croisée pour un certain nombre de configurations d'hyper-paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random_search = RandomizedSearchCV(\n",
    "                                    estimator=rf_pipeline, \n",
    "                                    param_distributions=rf_random_grid,\n",
    "                                    scoring=\"r2\",\n",
    "                                    n_iter=100, \n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    random_state=42,\n",
    "                                    n_jobs=6\n",
    "                                )\n",
    "\n",
    "rf_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e743407",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best score: {round(rf_random_search.best_score_, 2)}\")\n",
    "pp.pprint(rf_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b72a1",
   "metadata": {},
   "source": [
    "Nous observons un gain supplémentaire de performance par l'utilisation d'un odèle ensembliste. \n",
    "\n",
    "Comme nous l'avons fait précédemment pour l'arbre de décision, affichons l'importance relative des features pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = rf_pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "rf_features_importance = np.around(rf_random_search.best_estimator_.named_steps[\"model\"].feature_importances_, decimals=2)\n",
    "\n",
    "rf_fi_df = pd.DataFrame(data={\"name\": features_name, \"importance\": rf_features_importance})\n",
    "\n",
    "sns.color_palette(\"pastel\")\n",
    "sns.barplot(x=\"importance\", y=\"name\", data=rf_fi_df, orient=\"h\")\n",
    "plt.xlabel(\"Relative Importance (%)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439d57b6",
   "metadata": {},
   "source": [
    "Les mêmes features se démarquent, avec des importances relatives à peu près similaires.\n",
    "\n",
    "Évaluons enfin ce modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f07206",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictions = rf_random_search.predict(X_test)\n",
    "random_forest_metrics = metrics(y_test, rf_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b721afca",
   "metadata": {},
   "source": [
    "Le score r2 est similaire pour le jeu de test par rapport au jeu d'entraînement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402c4a4",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56e4d6c",
   "metadata": {},
   "source": [
    "Pour finir, nous choisissons l'algorithme de Gradient Boosting. Celui-ci se base sur un ensemble d'arbres de décision mais sa méthode est différente de celle d'un Random Forest, lui permettant souvent de fournir un gain de performance.\n",
    "\n",
    "Nous créons un nouveau pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65238272",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", GradientBoostingRegressor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cc29a",
   "metadata": {},
   "source": [
    "Nous définissons un espace d'hyper-paramètres spécifiques à ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52edfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_random_grid = {\n",
    "    \"model__loss\": [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"],\n",
    "    \"model__learning_rate\": [0.01, 0.05, 0.1, 0.5],\n",
    "    \"model__n_estimators\": [int(x) for x in np.linspace(start=50, stop=500, num=10)],\n",
    "    \"model__subsample\": list(np.linspace(start=0.5, stop=1, num=6)),\n",
    "    \"model__criterion\": [\"friedman_mse\", \"squared_error\"],\n",
    "    \"model__max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "    \"model__max_depth\": [int(x) for x in np.linspace(2, 10, num=8)],\n",
    "    \"model__min_samples_split\": [int(x) for x in np.linspace(2, 50, num=10)],\n",
    "    \"model__min_samples_leaf\": [int(x) for x in np.linspace(1, 50, num=10)]\n",
    "}\n",
    "\n",
    "pp.pprint(gb_random_grid)\n",
    "\n",
    "total_conf = 1\n",
    "for _, value in gb_random_grid.items():\n",
    "    if isinstance(value, list):\n",
    "        total_conf *= len(value)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"Total number of configurations: {total_conf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e7f897",
   "metadata": {},
   "source": [
    "Et nous entraînons le modèle en validation croisée sur plusieurs de ces configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4ee6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_random_search = RandomizedSearchCV(\n",
    "                                    estimator=gb_pipeline, \n",
    "                                    param_distributions=gb_random_grid,\n",
    "                                    scoring=\"r2\",\n",
    "                                    n_iter=200, \n",
    "                                    cv=5,\n",
    "                                    verbose=1,\n",
    "                                    random_state=42,\n",
    "                                    n_jobs=6\n",
    "                                )\n",
    "\n",
    "gb_random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15afe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best score: {round(gb_random_search.best_score_, 2)}\")\n",
    "pp.pprint(gb_random_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be34b68e",
   "metadata": {},
   "source": [
    "Le score obtenu sur le jeu d'entraînement est légèrement supérieur au score obtenu avec le Random Forest.\n",
    "\n",
    "Nous affichons l'importance relative des features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8fb6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = gb_pipeline.named_steps[\"preprocessor\"].get_feature_names_out()\n",
    "gb_features_importance = np.around(gb_random_search.best_estimator_.named_steps[\"model\"].feature_importances_, decimals=2)\n",
    "\n",
    "gb_fi_df = pd.DataFrame(data={\"name\": features_name, \"importance\": gb_features_importance})\n",
    "\n",
    "sns.color_palette(\"pastel\")\n",
    "sns.barplot(x=\"importance\", y=\"name\", data=gb_fi_df, orient=\"h\")\n",
    "plt.xlabel(\"Relative Importance (%)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea5ab7",
   "metadata": {},
   "source": [
    "Les relations d'importance de chaque feature sont les mêmes que précédemment.\n",
    "\n",
    "Nous finissons par évaluer le modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214091dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_predictions = gb_random_search.predict(X_test)\n",
    "gradient_boosting_metrics = metrics(y_test, gb_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3863392e",
   "metadata": {},
   "source": [
    "### Comparaison des Modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2a29bd",
   "metadata": {},
   "source": [
    "Afin de pouvoir mieux comparer les performances de chaque modèle, nous affichons dans un même dataframe les metrics calculées pour chaque modèle sur le jeu de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98508af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"Linear Regression\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Gradient Boosting\"\n",
    "]\n",
    "\n",
    "d = [\n",
    "    lr_metrics,\n",
    "    dt_metrics,\n",
    "    rf_metrics,\n",
    "    gb_metrics\n",
    "]\n",
    "\n",
    "pd.DataFrame(data=d, index=models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52195ab",
   "metadata": {},
   "source": [
    "Comme nous avons pu le constater, le modèle le plus performant est le Gradient Boosting Regressor. Celui-ci se base sur un ensemble d'arbres de décision comme peux le faire un Random Forest, mais ceux-ci sont moins profonds et la façon dont ils sont construits et leurs résultats aggrégés est différente. Cela lui permet de souvent mieux performer qu'un Random Forest, comme nous pouvons le voir ici."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543a3aaa",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d04ed8",
   "metadata": {},
   "source": [
    "Lors de ce projet, nous avons testé 4 modèles de complexité croissante. Pour chaque modèle (à part la régression linéaire), nous avons implémenté un RandomizedSearch en validation croisée sur un ensemble d'hyper-paramètres afin d'optimiser leurs performances.\n",
    "\n",
    "Le modèle le plus performant est le GradientBoostingRegressor.\n",
    "\n",
    "En analysant l'importance relative des features dans les prédictions de ces modèles, nous avons pu observer que les variables `hour` et `atemp` sortent du lot. Ces deux variables ont donc un poids plus fort dans la prédiction. Cela confirme nos analyses préliminaires, lors desquelles nous avions vu que le nombre total de locations est très dépendant de l'heure de la journée et de la température.\n",
    "\n",
    "Quelques axes d'amélioration pour la suite:\n",
    "- entraînement d'un modèle XGBoost, qui est une version plus régularisée du Gradient Boosting, et pourrait ainsi apporter un gain de performance en test.\n",
    "- affiner la recherche d'hyperparamètres en implémentant un GridSearchCV en validation croisée et en itérant sur un espace de paramètres plus en plus réduit.\n",
    "- tester d'autres méthodes de feature engineering."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
